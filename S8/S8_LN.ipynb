{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aai\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from datasets import load_data\n",
    "from model import model_summary,S8_Model_LN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('S8/util.py')\n",
    "from util import test, train, plot_acc_loss\n",
    "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader ,  test_loader  = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S8_Model_LN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(S8_Model_LN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7, padding=3, bias=False),\n",
    "            nn.LayerNorm([8,32,32 ]), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.10),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 4, kernel_size=3, padding=1),\n",
    "            nn.LayerNorm([4, 32,32]), \n",
    "            nn.ReLU(),\n",
    "             nn.Dropout(0.10),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv1x1_3 = nn.Sequential(\n",
    "                        nn.Conv2d(4, 8, kernel_size=1),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.pool_1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(8, 4, kernel_size=3, padding=1),\n",
    "            nn.LayerNorm([4,16,16]),  # Adjust for post-pooling size\n",
    "            nn.ReLU(),\n",
    "                        nn.Dropout(0.10),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(4, 10, kernel_size=3, padding=1),\n",
    "            nn.LayerNorm([10,16,16]),\n",
    "            nn.ReLU(),\n",
    "                        nn.Dropout(0.10),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(10, 8, kernel_size=3, padding=1),\n",
    "            nn.LayerNorm([8, 16,16]),\n",
    "            nn.ReLU(),\n",
    "                        nn.Dropout(0.10),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv1x1_7 = nn.Sequential(\n",
    "            nn.Conv2d(8, 8, kernel_size=1),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.pool_2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv2d(8, 10, kernel_size=3, padding=1),\n",
    "            nn.LayerNorm([10,8,8]),\n",
    "                        nn.Dropout(0.10),\n",
    "                        nn.ReLU(),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv2d(10, 16, kernel_size=3, padding=1),\n",
    "            nn.LayerNorm([16,8,8]),\n",
    "                        nn.Dropout(0.10),\n",
    "                        nn.ReLU(),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.Conv2d(16, 4, kernel_size=1, padding=1),\n",
    "                        nn.Dropout(0.10),\n",
    "                        nn.LayerNorm([4,10,10]),\n",
    "                        nn.ReLU(),\n",
    "\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv1x1_11 = nn.Sequential(\n",
    "            nn.Conv2d(4, 10, kernel_size=1),\n",
    "            \n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv1x1_3(x)\n",
    "        x = self.pool_1(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv1x1_7(x)\n",
    "        x = self.pool_2(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.conv1x1_11(x)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 32, 32]           1,176\n",
      "         LayerNorm-2            [-1, 8, 32, 32]          16,384\n",
      "              ReLU-3            [-1, 8, 32, 32]               0\n",
      "           Dropout-4            [-1, 8, 32, 32]               0\n",
      "            Conv2d-5            [-1, 4, 32, 32]             292\n",
      "         LayerNorm-6            [-1, 4, 32, 32]           8,192\n",
      "              ReLU-7            [-1, 4, 32, 32]               0\n",
      "           Dropout-8            [-1, 4, 32, 32]               0\n",
      "            Conv2d-9            [-1, 8, 32, 32]              40\n",
      "        MaxPool2d-10            [-1, 8, 16, 16]               0\n",
      "           Conv2d-11            [-1, 4, 16, 16]             292\n",
      "        LayerNorm-12            [-1, 4, 16, 16]           2,048\n",
      "             ReLU-13            [-1, 4, 16, 16]               0\n",
      "          Dropout-14            [-1, 4, 16, 16]               0\n",
      "           Conv2d-15           [-1, 10, 16, 16]             370\n",
      "        LayerNorm-16           [-1, 10, 16, 16]           5,120\n",
      "             ReLU-17           [-1, 10, 16, 16]               0\n",
      "          Dropout-18           [-1, 10, 16, 16]               0\n",
      "           Conv2d-19            [-1, 8, 16, 16]             728\n",
      "        LayerNorm-20            [-1, 8, 16, 16]           4,096\n",
      "             ReLU-21            [-1, 8, 16, 16]               0\n",
      "          Dropout-22            [-1, 8, 16, 16]               0\n",
      "           Conv2d-23            [-1, 8, 16, 16]              72\n",
      "        MaxPool2d-24              [-1, 8, 8, 8]               0\n",
      "           Conv2d-25             [-1, 10, 8, 8]             730\n",
      "        LayerNorm-26             [-1, 10, 8, 8]           1,280\n",
      "          Dropout-27             [-1, 10, 8, 8]               0\n",
      "             ReLU-28             [-1, 10, 8, 8]               0\n",
      "           Conv2d-29             [-1, 16, 8, 8]           1,456\n",
      "        LayerNorm-30             [-1, 16, 8, 8]           2,048\n",
      "          Dropout-31             [-1, 16, 8, 8]               0\n",
      "             ReLU-32             [-1, 16, 8, 8]               0\n",
      "           Conv2d-33            [-1, 4, 10, 10]              68\n",
      "          Dropout-34            [-1, 4, 10, 10]               0\n",
      "        LayerNorm-35            [-1, 4, 10, 10]             800\n",
      "             ReLU-36            [-1, 4, 10, 10]               0\n",
      "AdaptiveAvgPool2d-37              [-1, 4, 1, 1]               0\n",
      "           Conv2d-38             [-1, 10, 1, 1]              50\n",
      "================================================================\n",
      "Total params: 45,242\n",
      "Trainable params: 45,242\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.71\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = S8_Model_LN().to(device)\n",
    "model_summary(model,input_size= (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=2.3042 Batch_id=97 Accuracy=10.19: 100%|██████████| 98/98 [00:15<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0046, Accuracy: 1063/10000 (10.63%)\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=2.2921 Batch_id=97 Accuracy=12.02: 100%|██████████| 98/98 [00:14<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0046, Accuracy: 1192/10000 (11.92%)\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: Loss=2.2729 Batch_id=40 Accuracy=13.88:  42%|████▏     | 41/98 [00:11<00:15,  3.59it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m   \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_sgd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m   test(model, device, test_loader, criterion)\n\u001b[0;32m     11\u001b[0m   scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\ERA\\Assignment\\S8\\util.py:43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[0;32m     42\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 43\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(data)\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:489\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m     dynamo_config_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    491\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\optimizer.py:815\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    813\u001b[0m     per_device_and_dtype_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 815\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_zero_grad_profile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_groups\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\autograd\\profiler.py:605\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = F.nll_loss\n",
    "num_epochs = 20\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01,momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_sgd,gamma=0.99,step_size=5)\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  print(f'Epoch {epoch}')\n",
    "  train(model, device, train_loader, optimizer_sgd,criterion)\n",
    "  test(model, device, test_loader, criterion)\n",
    "  scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_adam = optim.Adam(model.parameters(), lr=1e-4,weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_adam, step_size=5, gamma=0.1, verbose=True)\n",
    "criterion = F.nll_loss\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  print(f'Epoch {epoch}')\n",
    "  train(model, device, train_loader, optimizer_adam,criterion)\n",
    "  test(model, device, test_loader, criterion)\n",
    "  scheduler.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_visualize_misclassified_images(model, device, test_loader, criterion, classes, num_images=10):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    misclassified_images = []\n",
    "    misclassified_true = []\n",
    "    misclassified_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            misclassified_idxs = (preds != target).nonzero(as_tuple=False).squeeze()\n",
    "\n",
    "            for idx in misclassified_idxs:\n",
    "                if len(misclassified_images) < num_images:\n",
    "                    misclassified_images.append(data[idx].cpu())\n",
    "                    misclassified_true.append(target[idx].cpu())\n",
    "                    misclassified_pred.append(preds[idx].cpu())\n",
    "                else:\n",
    "                    plot_misclassified_images(misclassified_images, misclassified_true, misclassified_pred, classes)\n",
    "                    return\n",
    "    if misclassified_images:\n",
    "        plot_misclassified_images(misclassified_images, misclassified_true, misclassified_pred, classes)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_misclassified_images(images, true_labels, predicted_labels, classes):\n",
    "    fig, axes = plt.subplots((len(images) + 1) // 2, 2, figsize=(10, 20))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(images):\n",
    "            img = images[i].numpy().transpose((1, 2, 0))\n",
    "            img = (img - img.min()) / (img.max() - img.min())  # Normalize to [0,1]\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"True: {classes[true_labels[i].item()]}, Pred: {classes[predicted_labels[i].item()]}\")\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Assume 'model', 'device', 'test_loader', 'criterion', and 'classes' are already defined\n",
    "find_and_visualize_misclassified_images(model, device, test_loader, criterion, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
